{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ms2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9rtwae1-hBr"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "from gensim.models import FastText\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHriJgo0MWMY",
        "outputId": "a7121791-72b2-43f9-d8da-467b6cf123bf"
      },
      "source": [
        "!pip install rouge"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX1OpRY0-q1y",
        "outputId": "c3077eef-d03d-492f-8d9c-dc72bf123c23"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gFlpXl0-3fh",
        "outputId": "9f835a90-27cd-444c-c1f2-48f438f4a522"
      },
      "source": [
        "data = pd.read_csv('/content/drive/Shareddrives/PMDL-spring21/Phase 2/Reviews.csv')\n",
        "len(data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "568454"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SgDGfVC_pO5"
      },
      "source": [
        "x = data['Text']\n",
        "y = data['Summary']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tknGybZW_qGn"
      },
      "source": [
        "def clean(text):\n",
        "  text = str(text)\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'\\'s',r'\\tis',text)\n",
        "  text = re.sub(r'\\'ll',r'\\twill',text)\n",
        "  text = re.sub(r'\\'m',r'\\tam',text)\n",
        "  text = re.sub(r'\\'re',r'\\tare',text)\n",
        "  text = re.sub(r'\\'d',r'\\twould',text)\n",
        "  text = re.sub(r'n\\'t',r'\\tnot',text)\n",
        "  text = re.sub('[^a-zA-Z0-9]',' ',text) \n",
        "  text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
        "  return text"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNdP0Qzw_sdG",
        "outputId": "0cbcc721-2d6b-4627-d3f5-58d91b58b5a6"
      },
      "source": [
        "cleaned_source = list(map(clean,x))\n",
        "cleaned_summary = list(map(clean,y))\n",
        "\n",
        "for i in range(len(cleaned_summary)):\n",
        "    cleaned_summary[i] = \"<START> \" + cleaned_summary[i] + \" <END>\"\n",
        "    \n",
        "print(cleaned_source[11])\n",
        "print(cleaned_summary[11])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "one of my boys needed to lose some weight and the other did not   i put this food on the floor for the chubby guy  and the protein rich  no by product food up higher where only my skinny boy can jump   the higher food sits going stale   they both really go for this food   and my chubby boy has been losing about an ounce a week \n",
            "<START> my cats love this  diet  food better than their regular food <END>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6j2HcI5_x6U",
        "outputId": "06fa57e5-c189-49cd-9e6d-c248386122e0"
      },
      "source": [
        "min_source_length = 1999999\n",
        "max_source_length = 0\n",
        "min_target_length = 199999\n",
        "max_target_length = 0\n",
        "\n",
        "for i in range(len(data)):\n",
        "  min_source_length = min(min_source_length,len(cleaned_source[i].split()))\n",
        "  min_target_length = min(min_target_length,len(cleaned_summary[i].split()))\n",
        "  max_source_length = max(max_source_length,len(cleaned_source[i].split()))\n",
        "  max_target_length = max(max_target_length,len(cleaned_summary[i].split()))\n",
        "\n",
        "print(\"Minimum source length is:  \",min_source_length)\n",
        "print(\"Minimum target length is:  \",min_target_length)\n",
        "print(\"Maximum source length is:  \",max_source_length)\n",
        "print(\"Maximum target length is:  \",max_target_length)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum source length is:   3\n",
            "Minimum target length is:   2\n",
            "Maximum source length is:   3529\n",
            "Maximum target length is:   50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiBn9oT1_2At",
        "outputId": "f5ce483e-07ed-4ae7-d580-c15c90d69407"
      },
      "source": [
        "new_source = []\n",
        "new_summary = []\n",
        "\n",
        "for i in range(len(cleaned_source)):\n",
        "  if len(cleaned_source[i].split()) <= 50 and len(cleaned_summary[i].split()) <= 15 :\n",
        "    new_source.append(cleaned_source[i])\n",
        "    new_summary.append(cleaned_summary[i])\n",
        "\n",
        "max_source_length = 50\n",
        "max_summary_length = 15\n",
        "\n",
        "print(len(new_source))\n",
        "print(len(new_summary))\n",
        "\n",
        "new_source = new_source[:30000]\n",
        "new_summary = new_summary[:30000]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "245024\n",
            "245024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-TbCAsM_47W",
        "outputId": "8ed7ff8d-5f11-4350-e829-5a6a0485b9cc"
      },
      "source": [
        "sentences = new_source + new_summary\n",
        "sent_ted = []\n",
        "for sent in sentences:\n",
        "  sent_ted_child = sent.split()\n",
        "  sent_ted.append(sent_ted_child)\n",
        "\n",
        "print(sent_ted[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'have', 'bought', 'several', 'of', 'the', 'vitality', 'canned', 'dog', 'food', 'products', 'and', 'have', 'found', 'them', 'all', 'to', 'be', 'of', 'good', 'quality', 'the', 'product', 'looks', 'more', 'like', 'a', 'stew', 'than', 'a', 'processed', 'meat', 'and', 'it', 'smells', 'better', 'my', 'labrador', 'is', 'finicky', 'and', 'she', 'appreciates', 'this', 'product', 'better', 'than', 'most']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2GRi6ZS_8Jn",
        "outputId": "f147fab0-68ba-4ac2-cca3-a2a3b63beeb6"
      },
      "source": [
        "import pickle\n",
        "model_ted = pickle.load(open('/content/drive/Shareddrives/PMDL-spring21/Phase 2/128_emb.pkl', 'rb'))\n",
        "weights = model_ted.wv\n",
        "print(model_ted.wv.most_similar(\"milk\"))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('skim', 0.5355638265609741), ('milks', 0.5320084095001221), ('water', 0.5292779207229614), ('foggy', 0.5185288190841675), ('creamer', 0.5173667669296265), ('wipping', 0.5089503526687622), ('raisan', 0.5022526383399963), ('floz', 0.4988960325717926), ('truvia', 0.4962727725505829), ('frother', 0.4953957200050354)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2VM8t7l_86k"
      },
      "source": [
        "from collections import OrderedDict \n",
        "\n",
        "word2Index_enc = {}\n",
        "word2Index_dec = {}\n",
        "word2Index_dec_big = {}\n",
        "\n",
        "ind2Word_enc = {}\n",
        "ind2Word_dec = {}\n",
        "ind2Word_dec_big = {}\n",
        "\n",
        "word2PsuInd_dec = {}\n",
        "psuInd2Word_dec = {}\n",
        "\n",
        "encoder_paragraph = list(set((' '.join(new_source)).split()))\n",
        "\n",
        "decoder_paragraph_list = list((' '.join(new_summary)).split())\n",
        "decoder_dict = OrderedDict()\n",
        "for word in decoder_paragraph_list:\n",
        "  try:\n",
        "    decoder_dict[word] = decoder_dict[word] + 1\n",
        "  except:\n",
        "    decoder_dict[word] = 1\n",
        "\n",
        "ind2Word_enc[0] = '<UNK>'\n",
        "ind2Word_dec[0] = '<UNK>'\n",
        "word2Index_enc['<UNK>'] = 0\n",
        "word2Index_dec['<UNK>'] = 0\n",
        "ind2Word_dec_big[0] = '<UNK>'\n",
        "word2Index_dec_big['<UNK>'] = 0\n",
        "word2PsuInd_dec['<UNK>'] = 0\n",
        "psuInd2Word_dec[0] = '<UNK>'\n",
        "\n",
        "dec_index = 1\n",
        "for (decoder_dict_word, decoder_dict_number) in decoder_dict.items():\n",
        "  word2Index_dec_big[decoder_dict_word] = dec_index\n",
        "  ind2Word_dec_big[dec_index] = decoder_dict_word\n",
        "  if decoder_dict_number >= 3 :\n",
        "    word2Index_dec[decoder_dict_word] = dec_index\n",
        "    ind2Word_dec[dec_index] = decoder_dict_word\n",
        "    psuedo_index = len(word2PsuInd_dec.keys())\n",
        "    word2PsuInd_dec[decoder_dict_word] = psuedo_index\n",
        "    psuInd2Word_dec[psuedo_index] = decoder_dict_word\n",
        "  dec_index+=1\n",
        "\n",
        "enc_index = 1\n",
        "for index,word in enumerate(encoder_paragraph):\n",
        "  if word != ' ':\n",
        "    word2Index_enc[word] = enc_index\n",
        "    ind2Word_enc[enc_index] = word \n",
        "    enc_index+=1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRZO7-MOADT2"
      },
      "source": [
        "encoder_input = [[word2Index_enc[word] for word in sentence.split() if word in word2Index_enc.keys()] for sentence in new_source ]\n",
        "decoder_input = [[word2Index_dec_big[word] for word in sentence.split() if word in word2Index_dec_big.keys()] for sentence in new_summary ]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlJAKWPcAINT"
      },
      "source": [
        "encoder_tensor = [torch.tensor(li,dtype=torch.long,device=device).view(-1, 1) for li in encoder_input]\n",
        "decoder_tensor = [torch.tensor(li,dtype=torch.long,device=device).view(-1, 1) for li in decoder_input]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua0AKzOAAJct"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,input_vocab_size,hidden_size,num_layers=1,bidirectional=False):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.bidirectional = bidirectional\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "    self.gru_layer = nn.GRU(input_size = self.hidden_size,hidden_size = self.hidden_size,num_layers = self.num_layers)\n",
        "\n",
        "  def forward(self,input_,prev_hidden_state):\n",
        "    input_word = ind2Word_enc[input_.data.tolist()[0]]\n",
        "    embedded_outputs = torch.tensor(weights[input_word], device = device).view(1,1,-1)\n",
        "    output,prev_hidden_state = self.gru_layer(embedded_outputs,prev_hidden_state)  #output is batch_size times hidden_size\n",
        "    return output,prev_hidden_state\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(1,1,self.hidden_size,device=device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARltQ7OPAMuA"
      },
      "source": [
        "class AttentionDecoder(nn.Module):\n",
        "  def __init__(self,output_vocab_size,hidden_size,max_length_encoder,dropout_value,num_layers=1):\n",
        "      super(AttentionDecoder,self).__init__()\n",
        "      self.hidden_size = hidden_size\n",
        "      self.num_layers = num_layers\n",
        "      self.output_vocab_size = output_vocab_size\n",
        "      self.dropout_p = dropout_value\n",
        "      self.max_length_encoder = max_length_encoder\n",
        "      self.embedding_layer = nn.Embedding(self.output_vocab_size,self.hidden_size)\n",
        "      self.attention_layer = nn.Linear(self.hidden_size*2,self.max_length_encoder)\n",
        "      self.attention_combine = nn.Linear(self.hidden_size*2,self.hidden_size)\n",
        "\n",
        "      self.s_layer = nn.Linear(self.hidden_size, 1)\n",
        "      self.x_layer = nn.Linear(self.hidden_size, 1)\n",
        "      self.context_layer = nn.Linear(self.hidden_size, 1)\n",
        "      self.linear_pgen = nn.Linear(3, 1)\n",
        "\n",
        "      self.gru_layer = nn.GRU(self.hidden_size,self.hidden_size)\n",
        "      self.output_layer = nn.Linear(self.hidden_size,self.output_vocab_size)\n",
        "      self.dropout_layer = nn.Dropout(self.dropout_p)    \n",
        "\n",
        "  def forward(self,input_,prev_hidden_state,encoder_output,prev_unk_word):\n",
        "      input_word = ind2Word_dec_big[input_.data.tolist()[0]]\n",
        "      if input_word == '<UNK>':\n",
        "        embedded_outputs = torch.tensor(weights[prev_unk_word], device = device).view(1,1,-1)\n",
        "      else:\n",
        "        embedded_outputs = torch.tensor(weights[input_word], device = device).view(1,1,-1)\n",
        "        \n",
        "      embeddings_dropout = self.dropout_layer(embedded_outputs)\n",
        "      attention_layer_output = self.attention_layer(torch.cat((embeddings_dropout[0],prev_hidden_state[0]),1))\n",
        "      attention_weights = nn.functional.softmax(attention_layer_output,dim=1)\n",
        "      attention_applied = torch.bmm(attention_weights.unsqueeze(0),encoder_output.unsqueeze(0))\n",
        "      attention_combine_logits = self.attention_combine(torch.cat((embeddings_dropout[0],attention_applied[0]),1)).unsqueeze(0)  #since gru requires a batch dimension\n",
        "      attention_combine_relu = nn.functional.relu(attention_combine_logits)\n",
        "\n",
        "      s_output = self.s_layer(prev_hidden_state[0])\n",
        "      x_output = self.x_layer(embeddings_dropout[0])\n",
        "      context = torch.flatten(attention_applied)\n",
        "      context_weights = self.context_layer(attention_applied)\n",
        "      sx = torch.cat((s_output[0],x_output[0]),0)\n",
        "      sxc = torch.cat((sx,context_weights[0][0]),0)\n",
        "      linear_pgen = self.linear_pgen(sxc)\n",
        "      m = nn.Sigmoid()\n",
        "      pgen = m(linear_pgen)\n",
        "\n",
        "      output,hidden = self.gru_layer(attention_combine_relu,prev_hidden_state)\n",
        "      output_logits = self.output_layer(output)\n",
        "      output_softmax = nn.functional.log_softmax(output_logits[0],dim=1)\n",
        "      return output_softmax,hidden,attention_weights,pgen\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(1,1,self.hidden_size,device=device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-Sl4xoCATZg"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def train(encoder, decoder, input_tensor, target_tensor, encoder_optimizer, decoder_optimizer, criterion, max_length, iters):\n",
        "\n",
        "  encoder_optimizer.zero_grad()\n",
        "  decoder_optimizer.zero_grad()\n",
        "\n",
        "  prev_unk_word = ''\n",
        "\n",
        "  encoder_hidden = encoder.init_hidden()\n",
        "\n",
        "  encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device = device)\n",
        "\n",
        "  input_length = input_tensor.size(0)\n",
        "  output_length = target_tensor.size(0)\n",
        "\n",
        "  loss = 0\n",
        "\n",
        "  for encoder_index in range(0, input_length):\n",
        "    encoder_output,encoder_hidden = encoder(input_tensor[encoder_index], encoder_hidden)\n",
        "    encoder_outputs[encoder_index] = encoder_output[0,0]\n",
        "\n",
        "  decoder_input = torch.tensor([word2Index_dec['<START>']],device=device)   \n",
        "  decoder_hidden = encoder_hidden\n",
        "  use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "  extended_vocab = psuInd2Word_dec.copy()\n",
        "  reverse_extended_vocab = word2PsuInd_dec.copy()\n",
        "  duplicate_words = {}\n",
        "  extend_key = len(word2Index_dec.keys())\n",
        "  input_list = input_tensor.tolist()\n",
        "  i =0\n",
        "  for input_word in input_list:\n",
        "    if ind2Word_enc[input_word[0]] in word2Index_dec.keys():\n",
        "      duplicate_words[i] = word2PsuInd_dec[ind2Word_enc[input_word[0]]]\n",
        "    else:\n",
        "      extended_vocab[extend_key] = ind2Word_enc[input_word[0]]\n",
        "      reverse_extended_vocab[ind2Word_enc[input_word[0]]] = extend_key\n",
        "      extend_key += 1\n",
        "    i = i+1\n",
        "\n",
        "  if use_teacher_forcing:\n",
        "    for decoder_index in range(output_length):\n",
        "      decoder_output,decoder_hidden,decoder_attention,pgen = decoder(decoder_input,decoder_hidden,encoder_outputs,prev_unk_word)\n",
        "      P_over_extended_vocab = torch.exp(decoder_output)*pgen.expand_as(torch.exp(decoder_output))\n",
        "\n",
        "      decoder_attention = decoder_attention.squeeze(0)[0:input_length].unsqueeze(0)\n",
        "      p_duplicate_list = torch.zeros([input_length, P_over_extended_vocab.size(1)], device=device)\n",
        "      p_duplicate_list = p_duplicate_list.tolist()\n",
        "      for (duplicate_word_key,duplicate_word_value) in duplicate_words.items():\n",
        "        p_duplicate_list[duplicate_word_key][duplicate_word_value] = 1\n",
        "      p_duplicate = torch.tensor(p_duplicate_list, dtype=torch.float, device=device)\n",
        "      p_diag = torch.mm(decoder_attention, p_duplicate)\n",
        "      p_diag = p_diag*(torch.tensor([1], device=device).sub(pgen)).expand_as(p_diag)\n",
        "      p_add_diag = torch.diag(p_diag.squeeze(0),diagonal=0)\n",
        "      P_over_extended_vocab = torch.mm(P_over_extended_vocab,p_add_diag).add(P_over_extended_vocab)\n",
        "\n",
        "      for i in range(input_length):\n",
        "        if not (1 in p_duplicate_list[i]):\n",
        "          P_over_extended_vocab = torch.cat((P_over_extended_vocab[0], torch.mm(decoder_attention.squeeze(0)[i].unsqueeze(0).unsqueeze(0), torch.tensor([1], device=device).sub(pgen).unsqueeze(0)).squeeze(0)),0).unsqueeze(0)\n",
        "\n",
        "      try:\n",
        "        loss += -torch.log(P_over_extended_vocab[0][ reverse_extended_vocab[ ind2Word_dec_big[ target_tensor[decoder_index].item() ] ] ] + 1e-12)\n",
        "        loss.backward(retain_graph=True)\n",
        "      except KeyError:\n",
        "        loss += torch.tensor(0,dtype=torch.float,device=device)\n",
        "      decoder_input = target_tensor[decoder_index]\n",
        "  else:\n",
        "\n",
        "    for decoder_index in range(output_length):\n",
        "      decoder_output,decoder_hidden,decoder_attention,pgen = decoder(decoder_input,decoder_hidden,encoder_outputs,prev_unk_word) \n",
        "      P_over_extended_vocab = torch.exp(decoder_output)*pgen.expand_as(torch.exp(decoder_output))\n",
        "\n",
        "      decoder_attention = decoder_attention.squeeze(0)[0:input_length].unsqueeze(0)\n",
        "      p_duplicate_list = torch.zeros([input_length, P_over_extended_vocab.size(1)], device=device)\n",
        "      p_duplicate_list = p_duplicate_list.tolist()\n",
        "      for (duplicate_word_key,duplicate_word_value) in duplicate_words.items():\n",
        "        p_duplicate_list[duplicate_word_key][duplicate_word_value] = 1\n",
        "      p_duplicate = torch.tensor(p_duplicate_list, dtype=torch.float, device=device)\n",
        "      p_diag = torch.mm(decoder_attention, p_duplicate)\n",
        "      p_diag = p_diag*(torch.tensor([1], device=device).sub(pgen)).expand_as(p_diag)\n",
        "      p_add_diag = torch.diag(p_diag.squeeze(0),diagonal=0)\n",
        "      P_over_extended_vocab = torch.mm(P_over_extended_vocab,p_add_diag).add(P_over_extended_vocab)\n",
        "\n",
        "      for i in range(input_length):\n",
        "        if not (1 in p_duplicate_list[i]):\n",
        "          P_over_extended_vocab = torch.cat((P_over_extended_vocab[0], torch.mm(decoder_attention.squeeze(0)[i].unsqueeze(0).unsqueeze(0), torch.tensor([1], device=device).sub(pgen).unsqueeze(0)).squeeze(0)),0).unsqueeze(0)\n",
        "\n",
        "      try:\n",
        "        loss += -torch.log(P_over_extended_vocab[0][ reverse_extended_vocab[ ind2Word_dec_big[ target_tensor[decoder_index].item() ] ] ] + 1e-12)\n",
        "        loss.backward(retain_graph=True)\n",
        "      except KeyError:\n",
        "        loss += torch.tensor(0,dtype=torch.float,device=device)\n",
        "      idx = torch.topk(P_over_extended_vocab, k=1, dim=1)[1]\n",
        "      if idx.item() < len(word2Index_dec.keys()):   \n",
        "        decoder_input = torch.tensor([idx.item()],dtype=torch.long,device=device)\n",
        "      elif idx.item() >= len(word2Index_dec.keys()):\n",
        "        prev_unk_word = extended_vocab[idx.item()]\n",
        "        decoder_input = torch.tensor([0],dtype=torch.long,device=device)\n",
        "      elif (decoder_input.item() == word2Index_dec['<END>']):\n",
        "        break\n",
        "\n",
        "  if iters > 20000:\n",
        "    torch.nn.utils.clip_grad_norm_(rnn_encoder.parameters(),0.4)\n",
        "    torch.nn.utils.clip_grad_norm_(rnn_decoder.parameters(),0.4)\n",
        "\n",
        "  encoder_optimizer.step()\n",
        "  decoder_optimizer.step()\n",
        "\n",
        "  return loss.item()/output_length"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mye_kgb6AX-u"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    if percent != 0:\n",
        "      es = s / (percent)\n",
        "      rs = es - s\n",
        "      return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "    else:\n",
        "      return 0"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd4mI-JWAbwQ",
        "outputId": "c07b0c32-1b5d-49b7-d151-d47c461bba1c"
      },
      "source": [
        "arr = np.arange(len(encoder_tensor))\n",
        "np.random.shuffle(arr)\n",
        "len(arr)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1_CqF8yAeJj"
      },
      "source": [
        "# Dictionary for creating loss graph\n",
        "loss_graph = {}\n",
        "\n",
        "def train_Iters(encoder,decoder,n_iters,print_every=50, plot_every=100,learning_rate = 0.03):\n",
        "  # start = time.time()\n",
        "  plot_losses = []\n",
        "  print_loss_total = 0  # Reset every print_every\n",
        "  plot_loss_total = 0\n",
        "\n",
        "  encoder_optimizer = torch.optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "  decoder_optimizer = torch.optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "  training_pairs = [random.choice(pairs) for i in range(n_iters)]\n",
        "  \n",
        "  criterion = nn.NLLLoss()\n",
        "  for iters in range(n_iters):\n",
        "    training_pair = training_pairs[iters - 1]\n",
        "    input_tensor = training_pair[0]\n",
        "    target_tensor = training_pair[1]\n",
        "\n",
        "    input_tensor = torch.tensor(input_tensor, dtype=torch.long, device = device).view(-1, 1)\n",
        "    target_tensor = torch.tensor(target_tensor, dtype=torch.long, device = device).view(-1, 1)\n",
        "\n",
        "    loss = train(encoder,decoder,input_tensor,target_tensor,encoder_optimizer,decoder_optimizer,criterion,max_source_length, iters)\n",
        "    print_loss_total += loss\n",
        "    plot_loss_total += loss\n",
        "\n",
        "    if iters % print_every == 0:\n",
        "        print_loss_avg = print_loss_total / print_every\n",
        "        print_loss_total = 0\n",
        "        print('%s %d%%) %.4f' % (iters, iters / len(arr) * 100, print_loss_avg))\n",
        "\n",
        "        if iters > 0:\n",
        "          loss_graph[iters] = print_loss_avg\n",
        "\n",
        "    if iters % plot_every == 0:\n",
        "        plot_loss_avg = plot_loss_total / plot_every\n",
        "        plot_losses.append(plot_loss_avg)\n",
        "        plot_loss_total = 0\n",
        "\n",
        "        #return loss"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBFDC6uaAh_t"
      },
      "source": [
        "%matplotlib inline \n",
        "\n",
        "from matplotlib import pyplot\n",
        "pyplot.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    pyplot.figure()\n",
        "    fig, ax = pyplot.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    pyplot.plot(points)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTnQsMx8AlFY"
      },
      "source": [
        "pairs = []\n",
        "for enc,dec in zip(encoder_input,decoder_input):\n",
        "    pairs.append([enc,dec])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyCo8D-5AnOw",
        "outputId": "4540bb82-b5d7-4d0b-b71e-ea03ed4a00cf"
      },
      "source": [
        "hidden_size = 128\n",
        "rnn_encoder = Encoder(len(word2Index_enc.keys()),hidden_size).to(device=device)\n",
        "rnn_decoder = AttentionDecoder(len(word2Index_dec.keys()),hidden_size,max_source_length,0.2).to(device=device)\n",
        "\n",
        "train_Iters(rnn_encoder,rnn_decoder,5000)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0%) 0.1714\n",
            "50 0%) 5.6345\n",
            "100 0%) 5.8225\n",
            "150 0%) 4.8406\n",
            "200 0%) 4.6814\n",
            "250 0%) 4.6415\n",
            "300 1%) 4.4091\n",
            "350 1%) 4.1923\n",
            "400 1%) 4.2697\n",
            "450 1%) 4.0123\n",
            "500 1%) 4.4203\n",
            "550 1%) 4.1832\n",
            "600 2%) 4.1844\n",
            "650 2%) 4.0388\n",
            "700 2%) 3.8069\n",
            "750 2%) 4.5407\n",
            "800 2%) 4.2120\n",
            "850 2%) 4.2045\n",
            "900 3%) 4.3148\n",
            "950 3%) 4.0410\n",
            "1000 3%) 4.1084\n",
            "1050 3%) 4.1745\n",
            "1100 3%) 4.2969\n",
            "1150 3%) 4.1750\n",
            "1200 4%) 4.1161\n",
            "1250 4%) 4.0516\n",
            "1300 4%) 3.6885\n",
            "1350 4%) 3.8702\n",
            "1400 4%) 3.9003\n",
            "1450 4%) 4.0120\n",
            "1500 5%) 3.5711\n",
            "1550 5%) 4.0104\n",
            "1600 5%) 4.0868\n",
            "1650 5%) 4.1342\n",
            "1700 5%) 4.1491\n",
            "1750 5%) 4.1815\n",
            "1800 6%) 4.1689\n",
            "1850 6%) 3.7660\n",
            "1900 6%) 3.8036\n",
            "1950 6%) 4.0518\n",
            "2000 6%) 4.0994\n",
            "2050 6%) 4.1529\n",
            "2100 7%) 3.8653\n",
            "2150 7%) 4.4184\n",
            "2200 7%) 4.0327\n",
            "2250 7%) 3.8252\n",
            "2300 7%) 4.1519\n",
            "2350 7%) 4.1808\n",
            "2400 8%) 3.9145\n",
            "2450 8%) 3.8470\n",
            "2500 8%) 3.9639\n",
            "2550 8%) 3.8149\n",
            "2600 8%) 4.0914\n",
            "2650 8%) 4.0173\n",
            "2700 9%) 4.3018\n",
            "2750 9%) 3.9788\n",
            "2800 9%) 3.8191\n",
            "2850 9%) 4.2253\n",
            "2900 9%) 3.9007\n",
            "2950 9%) 3.9921\n",
            "3000 10%) 3.9084\n",
            "3050 10%) 3.7970\n",
            "3100 10%) 3.8932\n",
            "3150 10%) 4.0615\n",
            "3200 10%) 3.9086\n",
            "3250 10%) 4.1354\n",
            "3300 11%) 3.9208\n",
            "3350 11%) 4.1963\n",
            "3400 11%) 3.7439\n",
            "3450 11%) 3.7914\n",
            "3500 11%) 4.3653\n",
            "3550 11%) 4.2155\n",
            "3600 12%) 3.9416\n",
            "3650 12%) 3.9754\n",
            "3700 12%) 3.8386\n",
            "3750 12%) 3.9299\n",
            "3800 12%) 4.2880\n",
            "3850 12%) 4.0399\n",
            "3900 13%) 4.1122\n",
            "3950 13%) 3.6110\n",
            "4000 13%) 3.5216\n",
            "4050 13%) 3.2095\n",
            "4100 13%) 3.6363\n",
            "4150 13%) 3.8867\n",
            "4200 14%) 3.8032\n",
            "4250 14%) 3.9938\n",
            "4300 14%) 3.9179\n",
            "4350 14%) 4.1293\n",
            "4400 14%) 3.8714\n",
            "4450 14%) 3.8972\n",
            "4500 15%) 4.2052\n",
            "4550 15%) 3.9792\n",
            "4600 15%) 3.8665\n",
            "4650 15%) 3.7027\n",
            "4700 15%) 3.9942\n",
            "4750 15%) 4.0322\n",
            "4800 16%) 3.7289\n",
            "4850 16%) 3.8501\n",
            "4900 16%) 3.5986\n",
            "4950 16%) 3.9257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFO2SV1cApag",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "020da9eb-62fd-44cb-a2d6-107c4263a956"
      },
      "source": [
        "%matplotlib inline \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "iters = list(loss_graph.keys())\n",
        "loss_val = list(loss_graph.values())\n",
        "plt.plot(iters, loss_val)\n",
        "plt.ylim(0,8) \n",
        "plt.xlim(0,5000)\n",
        "plt.xlabel('Iterations') \n",
        "plt.ylabel('Loss')  \n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9BHiSBFArlw"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge import Rouge \n",
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        pair1 = torch.tensor(pair[0],dtype=torch.long,device=device)\n",
        "        pair2 = pair[1]\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair1)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        output_list = [ind2Word_dec_big[word] for word in pair2]\n",
        "        output_list = ' '.join(output_list)\n",
        "        input_sentence = [ind2Word_enc[element.item()] for element in pair1.flatten()]\n",
        "        input_sentence = ' '.join(input_sentence)\n",
        "        #print(\"Sentence is  \",input_sentence)\n",
        "        #print('<',output_sentence)\n",
        "        #print('=',output_list)\n",
        "        print(\"Review:\",input_sentence)\n",
        "        #print(\"Original summary:\",output_sentence)\n",
        "        print(\"Predicted summary:\",output_list)\n",
        "        scoreB = sentence_bleu(output_sentence, output_list)\n",
        "        rouge = Rouge()\n",
        "        scoreR = rouge.get_scores(output_sentence, output_list)\n",
        "        print(scoreB)\n",
        "        print(scoreR)\n",
        "        print(\"\\n\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATUPvCUtAu0u"
      },
      "source": [
        "def evaluate(encoder, decoder, encoder_tensor, max_length=max_source_length):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = encoder_tensor\n",
        "        input_length = input_tensor.size(0)\n",
        "        encoder_hidden = encoder.init_hidden()\n",
        "\n",
        "        prev_unk_word = ''\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0),\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        extended_vocab = psuInd2Word_dec.copy()\n",
        "        duplicate_words = {}\n",
        "        extend_key = len(word2Index_dec.keys())\n",
        "        input_list = input_tensor.tolist()\n",
        "        i =0\n",
        "        for input_word in input_list:\n",
        "          if ind2Word_enc[input_word] in word2Index_dec.keys():\n",
        "            duplicate_words[i] = word2PsuInd_dec[ind2Word_enc[input_word]]\n",
        "          else:\n",
        "            extended_vocab[extend_key] = ind2Word_enc[input_word]\n",
        "            extend_key += 1\n",
        "          i = i+1\n",
        "\n",
        "        decoder_input = torch.tensor([word2Index_dec['<START>']], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention,pgen = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs, prev_unk_word)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "\n",
        "            P_over_extended_vocab = torch.exp(decoder_output)*pgen.expand_as(torch.exp(decoder_output))\n",
        "\n",
        "            decoder_attention = decoder_attention.squeeze(0)[0:input_length].unsqueeze(0)\n",
        "            p_duplicate_list = torch.zeros([input_length, P_over_extended_vocab.size(1)], device=device)\n",
        "            p_duplicate_list = p_duplicate_list.tolist()\n",
        "            for (duplicate_word_key,duplicate_word_value) in duplicate_words.items():\n",
        "              p_duplicate_list[duplicate_word_key][duplicate_word_value] = 1\n",
        "            p_duplicate = torch.tensor(p_duplicate_list, dtype=torch.float, device=device)\n",
        "            p_diag = torch.mm(decoder_attention, p_duplicate)\n",
        "            p_diag = p_diag*(torch.tensor([1], device=device).sub(pgen)).expand_as(p_diag)\n",
        "            p_add_diag = torch.diag(p_diag.squeeze(0),diagonal=0)\n",
        "            P_over_extended_vocab = torch.mm(P_over_extended_vocab,p_add_diag).add(P_over_extended_vocab)\n",
        "\n",
        "            for i in range(input_length):\n",
        "              if not (1 in p_duplicate_list[i]):\n",
        "                P_over_extended_vocab = torch.cat((P_over_extended_vocab[0], torch.mm(decoder_attention.squeeze(0)[i].unsqueeze(0).unsqueeze(0), torch.tensor([1], device=device).sub(pgen).unsqueeze(0)).squeeze(0)),0).unsqueeze(0)\n",
        "\n",
        "            idx = torch.topk(P_over_extended_vocab, k=1, dim=1)[1]\n",
        "            if idx.item() < len(word2Index_dec.keys()):   \n",
        "              decoder_input = torch.tensor([idx.item()],dtype=torch.long,device=device)\n",
        "              decoded_words.append(extended_vocab[idx.item()])\n",
        "            elif idx.item() >= len(word2Index_dec.keys()):\n",
        "              decoder_input = torch.tensor([0],dtype=torch.long,device=device)\n",
        "              prev_unk_word = extended_vocab[idx.item()]\n",
        "              decoded_words.append(extended_vocab[idx.item()])\n",
        "            if idx.item() == word2Index_dec['<END>']:\n",
        "              decoded_words.append('<END>')\n",
        "              break\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZF518BRAz9t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f668b8f-fe7b-4b98-a04d-2b8a40e4e3be"
      },
      "source": [
        "evaluateRandomly(rnn_encoder, rnn_decoder)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: my daughter loved this cotton candy it was hard to find in the stores but am glad we found it online\n",
            "Predicted summary: <START> my daughter loved this <END>\n",
            "0.8034284189446518\n",
            "[{'rouge-1': {'f': 0.39999999520000007, 'p': 0.5, 'r': 0.3333333333333333}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.44444444000000005, 'p': 0.6666666666666666, 'r': 0.3333333333333333}}]\n",
            "\n",
            "\n",
            "Review: deliciously sweet and chocolate y while having essentially the same nutritional bang for your caloric buck as plain almonds a great product\n",
            "Predicted summary: <START> delicious <END>\n",
            "0.8316033157750904\n",
            "[{'rouge-1': {'f': 0.5714285665306124, 'p': 0.5, 'r': 0.6666666666666666}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.6666666616666668, 'p': 0.6666666666666666, 'r': 0.6666666666666666}}]\n",
            "\n",
            "\n",
            "Review: my children love the taste better than milk from grocery store and it is good for us to travel out of the country\n",
            "Predicted summary: <START> good product <END>\n",
            "0.8408964152537145\n",
            "[{'rouge-1': {'f': 0.4999999950000001, 'p': 0.5, 'r': 0.5}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.5714285665306124, 'p': 0.6666666666666666, 'r': 0.5}}]\n",
            "\n",
            "\n",
            "Review: my dogs love it even the little princess terrier i ve tried many other brands and they enjoy this one the most as so far\n",
            "Predicted summary: <START> dogs scarf it down <END>\n",
            "0.8132882808488929\n",
            "[{'rouge-1': {'f': 0.39999999520000007, 'p': 0.5, 'r': 0.3333333333333333}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.44444444000000005, 'p': 0.6666666666666666, 'r': 0.3333333333333333}}]\n",
            "\n",
            "\n",
            "Review: great price and delivered on time not beluga but i cannot afford that so this is a tasty alternative at a fraction of the cost\n",
            "Predicted summary: <START> good deal <END>\n",
            "0.8670694387164803\n",
            "[{'rouge-1': {'f': 0.4999999950000001, 'p': 0.5, 'r': 0.5}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.5714285665306124, 'p': 0.6666666666666666, 'r': 0.5}}]\n",
            "\n",
            "\n",
            "Review: very strong excellent taste if you want a coffee that is full of flavor even on the largest cup size this is the one to buy\n",
            "Predicted summary: <START> bold <END>\n",
            "0.8633400213704505\n",
            "[{'rouge-1': {'f': 0.5714285665306124, 'p': 0.5, 'r': 0.6666666666666666}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.6666666616666668, 'p': 0.6666666666666666, 'r': 0.6666666666666666}}]\n",
            "\n",
            "\n",
            "Review: this tastes nothing like pumpkin let alone pumpkin pie it just tastes like spicy cleaning solution to me some may be a fan but i am certainly not\n",
            "Predicted summary: <START> yuck <END>\n",
            "0.8633400213704505\n",
            "[{'rouge-1': {'f': 0.5714285665306124, 'p': 0.5, 'r': 0.6666666666666666}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.6666666616666668, 'p': 0.6666666666666666, 'r': 0.6666666666666666}}]\n",
            "\n",
            "\n",
            "Review: when you are in the mood for something savory these really fit the bill you get the richness of cashews contrasted with the bite of black pepper it is a unique combination and i give them five stars\n",
            "Predicted summary: <START> rich and bold <END>\n",
            "0.816496580927726\n",
            "[{'rouge-1': {'f': 0.4444444395061729, 'p': 0.5, 'r': 0.4}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.49999999531250006, 'p': 0.6666666666666666, 'r': 0.4}}]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Review: wolfgang puck is hawaiian hazelnut is the best k cup hazelnut and i have tried them all we ordered this large pack because we sadly found out that wolfgang puck is discontinuing many not all of their k cups including this flavor buy this while you can\n",
            "Predicted summary: <START> the best hazelnut k cup <END>\n",
            "0.7699019277569183\n",
            "[{'rouge-1': {'f': 0.36363635900826446, 'p': 0.5, 'r': 0.2857142857142857}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.3999999958, 'p': 0.6666666666666666, 'r': 0.2857142857142857}}]\n",
            "\n",
            "\n",
            "Review: i thought it was great if your want hot this is just for you just one word for this item great\n",
            "Predicted summary: <START> bhut jolokia powder <END>\n",
            "0.8070557274927981\n",
            "[{'rouge-1': {'f': 0.4444444395061729, 'p': 0.5, 'r': 0.4}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.49999999531250006, 'p': 0.6666666666666666, 'r': 0.4}}]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}