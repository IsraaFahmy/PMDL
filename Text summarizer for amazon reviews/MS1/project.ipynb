{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project",
      "provenance": [],
      "collapsed_sections": [
        "te05Y63DFpSW",
        "FSuGl2ioFvD5",
        "LrzKnmnoGd0f",
        "ZdcpnQ62Hbiy",
        "HmYsJPz5Huzt"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d504gzwJKZs"
      },
      "source": [
        "#Custom Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "a_AxnaUKKv8l",
        "outputId": "2bc2f443-af1e-4507-a65d-d7dfa39dafaa"
      },
      "source": [
        "from google.colab import files\n",
        "src = list(files.upload().values())[0]\n",
        "open('mylib.py','wb').write(src)\n",
        "import mylib"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-076d5f73-08d1-4791-9554-311093fca092\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-076d5f73-08d1-4791-9554-311093fca092\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving attention.py to attention.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-io2uChKxO8"
      },
      "source": [
        "from attention import AttentionLayer"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lwr8brKBstS"
      },
      "source": [
        "#Import Libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd78abgcBdZm"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxlYWx73CAUT"
      },
      "source": [
        "#Read the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_7-7cDVBrUn"
      },
      "source": [
        "data=pd.read_csv(\"/content/Reviews.csv\",nrows=10000)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdKCqYsrCGNj"
      },
      "source": [
        "#Drop Duplicates and NA values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC_W7Y7zCCPL"
      },
      "source": [
        "data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
        "data.dropna(axis=0,inplace=True)#dropping na"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NlmpahkCRB7"
      },
      "source": [
        "#Information about dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qar8hQSCMCf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d888a592-8694-4bcd-f694-a0192f30b29d"
      },
      "source": [
        "data.info()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 9513 entries, 0 to 9999\n",
            "Data columns (total 10 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   Id                      9513 non-null   int64 \n",
            " 1   ProductId               9513 non-null   object\n",
            " 2   UserId                  9513 non-null   object\n",
            " 3   ProfileName             9513 non-null   object\n",
            " 4   HelpfulnessNumerator    9513 non-null   int64 \n",
            " 5   HelpfulnessDenominator  9513 non-null   int64 \n",
            " 6   Score                   9513 non-null   int64 \n",
            " 7   Time                    9513 non-null   int64 \n",
            " 8   Summary                 9513 non-null   object\n",
            " 9   Text                    9513 non-null   object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 817.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBk8Nj-9Caq4"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW4EZZfLCTrK"
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ew4f8M5CgJ8"
      },
      "source": [
        "We will perform the below preprocessing tasks for our data:\n",
        "\n",
        "1.Convert everything to lowercase\n",
        "\n",
        "2.Remove HTML tags\n",
        "\n",
        "3.Contraction mapping\n",
        "\n",
        "4.Remove (‘s)\n",
        "\n",
        "5.Remove any text inside the parenthesis ( )\n",
        "\n",
        "6.Eliminate punctuations and special characters\n",
        "\n",
        "7.Remove stopwords\n",
        "\n",
        "8.Remove short words\n",
        "\n",
        "*Let’s define the function:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u8wBVFKawgx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3da5b0fe-29cb-489f-fe62-43c3cd8f8527"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Tj08HZaCcjg"
      },
      "source": [
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "def text_cleaner(text,num):\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
        "    if(num==0):\n",
        "        tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    else:\n",
        "        tokens=newString.split()\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                                 #removing short word\n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRzHx9U6CrCD"
      },
      "source": [
        "#call the function\n",
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t,0))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxPwcHZACvj3"
      },
      "source": [
        "\n",
        "Let us look at the first five preprocessed reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKIl5hAyCvHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b5d507-5bb0-4e67-fb6b-c3befe67d89b"
      },
      "source": [
        "cleaned_text[:5]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
              " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
              " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
              " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
              " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxXINp3zCyFB"
      },
      "source": [
        "#call the function\n",
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(text_cleaner(t,1))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GOQqhH-C45c"
      },
      "source": [
        "Let us look at the first 10 preprocessed summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-04FzOb3C7yl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76715534-0c6d-4bfc-84d2-e2293e305e2a"
      },
      "source": [
        "cleaned_summary[:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good quality dog food',\n",
              " 'not as advertised',\n",
              " 'delight says it all',\n",
              " 'cough medicine',\n",
              " 'great taffy',\n",
              " 'nice taffy',\n",
              " 'great just as good as the expensive brands',\n",
              " 'wonderful tasty taffy',\n",
              " 'yay barley',\n",
              " 'healthy dog food']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S88ogODDE7T"
      },
      "source": [
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pcU0LxFDJmk"
      },
      "source": [
        "#Drop empty rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWhVoTCmDHG8"
      },
      "source": [
        "data.replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-b1W-ADDPiv"
      },
      "source": [
        "#Understanding the distribution of the sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkNwxGRjDMYh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "562e9b4e-e664-4517-8bf8-5fa12650a48c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in data['cleaned_text']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in data['cleaned_summary']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvNqh6A9DYjs"
      },
      "source": [
        "We can fix the maximum length of the summary to 10 since that seems to be the majority summary length.\n",
        "\n",
        "Let us understand the proportion of the length of summaries below 8\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-l5aX-0DZUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7db382f-dc07-4f5e-f436-253056ed4af8"
      },
      "source": [
        "cnt=0\n",
        "for i in data['cleaned_summary']:\n",
        "    if(len(i.split())<=10):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(data['cleaned_summary']))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9800105207785376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9SYa4opDfya"
      },
      "source": [
        "We observe that 94% of the summaries have length below 8. \n",
        "\n",
        "So, we can fix maximum length of summary to 8.\n",
        "\n",
        "Let us fix the maximum length of review to 30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka_bloOJDbjJ"
      },
      "source": [
        "max_text_len=50\n",
        "max_summary_len=10"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF5dqkHlDygQ"
      },
      "source": [
        "Let us select the reviews and summaries whose length falls below or equal to **max_text_len** and **max_summary_len**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZNf-vIIDuds"
      },
      "source": [
        "cleaned_text =np.array(data['cleaned_text'])\n",
        "cleaned_summary=np.array(data['cleaned_summary'])\n",
        "\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "        \n",
        "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UBowNhFD-Y-"
      },
      "source": [
        "Remember to add the **START** and **END** special tokens at the beginning and end of the summary. \n",
        "\n",
        "Here, I have chosen **sostok** and **eostok** as START and END tokens\n",
        "\n",
        "**Note:** Be sure that the chosen special tokens never appear in the summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_qIqvRzEOM2"
      },
      "source": [
        "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOvpo19JEQdk"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9f96AKdEV6j"
      },
      "source": [
        "#Preparing the Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwJQnaLPEgJw"
      },
      "source": [
        "A tokenizer builds the vocabulary and converts a word sequence to an integer sequence. Go ahead and build tokenizers for text and summary:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMUrzDlSEmng"
      },
      "source": [
        "#Text Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa9RK-QFElHr"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIjLqXPIEtzJ"
      },
      "source": [
        "#Rarewords and its Coverage\n",
        "\n",
        "Let us look at the proportion rare words and its total coverage in the entire text.\n",
        "\n",
        "Here, I am defining the threshold to be 4 which means word whose count is below 4 is considered as a rare word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-JqFih3Ergy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07366492-c875-4463-fcbe-9f48aee6f394"
      },
      "source": [
        "thresh=4\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 66.24242424242425\n",
            "Total Coverage of rare words: 6.735458730966356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoWXVBdDE5Qw"
      },
      "source": [
        "Remember:\n",
        "\n",
        "* **tot_cnt** gives the size of vocabulary (which means every unique words in the text)\n",
        "\n",
        "* **cnt gives** me the no. of rare words whose count falls below threshold\n",
        "\n",
        "* **tot_cnt** - cnt gives me the top most common words\n",
        "\n",
        "Let us define the tokenizer with top most common words for reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjT4svB8E1CB"
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TIZltftFdYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "122caf11-447e-44ad-ee36-528f09203c21"
      },
      "source": [
        "x_voc"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3900"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te05Y63DFpSW"
      },
      "source": [
        "#Summary Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dibXv7MFFg4A"
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSuGl2ioFvD5"
      },
      "source": [
        "#Rarewords and its Coverage\n",
        "Let us look at the proportion rare words and its total coverage in the entire summary\n",
        "\n",
        "Here, I am defining the threshold to be 6 which means word whose count is below 6 is considered as a rare word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjCs9jOuFxd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b4811b-5ece-4e37-d4a8-d6f5cd7e44e4"
      },
      "source": [
        "thresh=6\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 82.42840095465394\n",
            "Total Coverage of rare words: 12.377543330821402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWy_c2-8F3ZV"
      },
      "source": [
        "Let us define the tokenizer with top most common words for summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj8D9NbdF0__"
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boPP9gmQF5TO"
      },
      "source": [
        "Let us check whether word count of start token is equal to length of the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p1-q8_8F7XZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc446110-b323-4e6d-ed51-9763a66f99fa"
      },
      "source": [
        "y_tokenizer.word_counts['sostok'],len(y_tr)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6738, 6738)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sRb6xMEGFeU"
      },
      "source": [
        "Here, I am deleting the rows that contain only **START** and **END** tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmgmIItNGD2H"
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy3E0RY7GSky"
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrzKnmnoGd0f"
      },
      "source": [
        "#Model building\n",
        "We are finally at the model building part. But before we do that, we need to familiarize ourselves with a few terms which are required prior to building the model.\n",
        "\n",
        "**Return Sequences = True:** When the return sequences parameter is set to True, LSTM produces the hidden state and cell state for every timestep\n",
        "\n",
        "**Return State = True:** When return state = True, LSTM produces the hidden state and cell state of the last timestep only\n",
        "\n",
        "**Initial State:** This is used to initialize the internal states of the LSTM for the first timestep\n",
        "\n",
        "**Stacked LSTM:** Stacked LSTM has multiple layers of LSTM stacked on top of each other. This leads to a better representation of the sequence. \n",
        "\n",
        "I encourage you to experiment with the multiple layers of the LSTM stacked on top of each other (it’s a great way to learn this)\n",
        "\n",
        "Here, we are building a 3 stacked LSTM for the encoder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8lHFQjTGssa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88fa8da3-004d-4053-c59e-ac28daa409ac"
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=100\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output3, state_h3, state_c3= encoder_lstm3(encoder_output2)\n",
        "\n",
        "#encoder lstm 4\n",
        "encoder_lstm4=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output4, state_h4, state_c4= encoder_lstm4(encoder_output3)\n",
        "\n",
        "#encoder lstm 5\n",
        "encoder_lstm5=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm5(encoder_output4)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 50, 100)      390000      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 50, 300), (N 481200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 50, 300), (N 721200      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 50, 300), (N 721200      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, 50, 300), (N 721200      lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    59000       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   [(None, 50, 300), (N 721200      lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
            "                                                                 lstm_4[0][1]                     \n",
            "                                                                 lstm_4[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_4[0][0]                     \n",
            "                                                                 lstm_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_5[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 590)    354590      concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 4,831,090\n",
            "Trainable params: 4,831,090\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIUeJevUHGYa"
      },
      "source": [
        "I am using sparse categorical cross-entropy as the loss function since it converts the integer sequence to a one-hot vector on the fly. This overcomes any memory issues."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3jZPOkWHFkQ"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',metrics='accuracy')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7RXxIsMHMhn"
      },
      "source": [
        "Remember the concept of early stopping? It is used to stop training the neural network at the right time by monitoring a user-specified metric. Here, I am monitoring the validation loss (val_loss). Our model will stop training once the validation loss increases:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NK_ec18HNnG"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-OZpP6-HTSw"
      },
      "source": [
        "We’ll train the model on a batch size of 128 and validate it on the holdout set (which is 10% of our dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRXsdFD9HUGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d9cab6a-ac74-4740-c671-79624fa88fab"
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "50/50 [==============================] - 71s 1s/step - loss: 3.1598 - accuracy: 0.5093 - val_loss: 1.9838 - val_accuracy: 0.6653\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 56s 1s/step - loss: 2.0712 - accuracy: 0.6689 - val_loss: 1.8727 - val_accuracy: 0.6945\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 54s 1s/step - loss: 1.9391 - accuracy: 0.6817 - val_loss: 1.8288 - val_accuracy: 0.6939\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 55s 1s/step - loss: 1.8929 - accuracy: 0.6835 - val_loss: 1.8188 - val_accuracy: 0.6951\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 56s 1s/step - loss: 1.8587 - accuracy: 0.6818 - val_loss: 1.7895 - val_accuracy: 0.6960\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 55s 1s/step - loss: 1.8217 - accuracy: 0.6829 - val_loss: 1.7758 - val_accuracy: 0.6949\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 54s 1s/step - loss: 1.8146 - accuracy: 0.6823 - val_loss: 1.7588 - val_accuracy: 0.6971\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 53s 1s/step - loss: 1.7699 - accuracy: 0.6865 - val_loss: 1.7494 - val_accuracy: 0.6970\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 54s 1s/step - loss: 1.7458 - accuracy: 0.6868 - val_loss: 1.7341 - val_accuracy: 0.6985\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 52s 1s/step - loss: 1.6940 - accuracy: 0.6922 - val_loss: 1.7121 - val_accuracy: 0.7019\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 54s 1s/step - loss: 1.6792 - accuracy: 0.6907 - val_loss: 1.6895 - val_accuracy: 0.7041\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 54s 1s/step - loss: 1.6476 - accuracy: 0.6937 - val_loss: 1.6877 - val_accuracy: 0.7047\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 53s 1s/step - loss: 1.6225 - accuracy: 0.6928 - val_loss: 1.6696 - val_accuracy: 0.7078\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 51s 1s/step - loss: 1.5774 - accuracy: 0.7001 - val_loss: 1.6614 - val_accuracy: 0.7090\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 51s 1s/step - loss: 1.5412 - accuracy: 0.7041 - val_loss: 1.6573 - val_accuracy: 0.7095\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 51s 1s/step - loss: 1.5286 - accuracy: 0.7014 - val_loss: 1.6421 - val_accuracy: 0.7101\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 52s 1s/step - loss: 1.4919 - accuracy: 0.7053 - val_loss: 1.6577 - val_accuracy: 0.7047\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 51s 1s/step - loss: 1.4635 - accuracy: 0.7080 - val_loss: 1.6418 - val_accuracy: 0.7095\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 52s 1s/step - loss: 1.4355 - accuracy: 0.7114 - val_loss: 1.6436 - val_accuracy: 0.7116\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 53s 1s/step - loss: 1.3912 - accuracy: 0.7163 - val_loss: 1.6469 - val_accuracy: 0.7090\n",
            "Epoch 00020: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdcpnQ62Hbiy"
      },
      "source": [
        "#Understanding the Diagnostic plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLDYHFB0HeMA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "53eb8731-895d-4bee-ed18-67eb90f37caa"
      },
      "source": [
        "\n",
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3HjagEvHnnB"
      },
      "source": [
        "From the plot, we can infer that validation loss has increased after epoch 17 for 2 successive epochs. Hence, training is stopped at epoch 19.\n",
        "\n",
        "Next, let’s build the dictionary to convert the index to word for target and source vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59p6VV0fjecf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11242256-4160-4852-b203-06d879493bdc"
      },
      "source": [
        "training_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "val_loss\n",
        "training_loss"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.5235514640808105,\n",
              " 2.01715087890625,\n",
              " 1.9347714185714722,\n",
              " 1.8916577100753784,\n",
              " 1.857790470123291,\n",
              " 1.8289629220962524,\n",
              " 1.8023923635482788,\n",
              " 1.7720468044281006,\n",
              " 1.7434910535812378,\n",
              " 1.71111261844635,\n",
              " 1.6810076236724854,\n",
              " 1.648982048034668,\n",
              " 1.6175116300582886,\n",
              " 1.5865153074264526,\n",
              " 1.5561110973358154,\n",
              " 1.5257502794265747,\n",
              " 1.4976634979248047,\n",
              " 1.4672951698303223,\n",
              " 1.4397075176239014,\n",
              " 1.4139666557312012]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHRrT1uzHq0I"
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmYsJPz5Huzt"
      },
      "source": [
        "#Inference\n",
        "\n",
        "Set up the inference for the encoder and decoder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-izElKcHyJP"
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ud-bMhSIJ-T"
      },
      "source": [
        "We are defining a function below which is the implementation of the inference process "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWSOP0aKH9pL"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeYsu3yCIGxB"
      },
      "source": [
        "Let us define the functions to convert an integer sequence to a word sequence for summary as well as the reviews:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snXkq-hPILFX"
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6ATxjgIba2B"
      },
      "source": [
        "#BLEU Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOKtxOVCbTML"
      },
      "source": [
        "import sys\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
        "\n",
        "def Bleu(pred_path, data_path):\n",
        "  if __name__ == \"__main__\":\n",
        "    n = int(sys.argv[1])\n",
        "    pred_path = sys.argv[2]\n",
        "    data_path = sys.argv[3]\n",
        "    weights = [1/n] * n + [0] * (4-n)\n",
        "    with open(pred_path, \"r\") as file:\n",
        "        pred = file.readlines()\n",
        "\n",
        "    with open(data_path, \"r\") as file:\n",
        "        target = file.readlines()\n",
        "    pred = [p.lower().split() for p in pred]\n",
        "    target = [[t.lower().split()] for t in target]\n",
        "    print(corpus_bleu(target, pred, weights=weights))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WIVMzB6IQ0_"
      },
      "source": [
        "Here are a few summaries generated by the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LvsBO6kITk3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71a795a5-cfce-4884-8dd0-27fc8dd0b92f"
      },
      "source": [
        "for i in range(0,50):\n",
        "    print(\"Review:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: purchased pods using amazon subscribe save program first time year order received promptly pods fresh flavorful used flavor coffee pods since january disappointed ever hopefully able continue receiving amazon \n",
            "Original summary: senseo coffee pods \n",
            "Predicted summary:  great coffee\n",
            "\n",
            "\n",
            "Review: beef jerky strips really good texture right flavor also right could smoky repeat buy part \n",
            "Original summary: good stuff \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: bag coffee shipped every month notice flavor vary time said worse plain great best roasts die noticed variation coffees always assumed minute roasting course bean plant hardly exact another plant perhaps weather count last year flavor taste consistent years back everyone different tastes close perfect gets \n",
            "Original summary: kona in \n",
            "Predicted summary:  love these\n",
            "\n",
            "\n",
            "Review: child memory drinking sassafras tea made fresh sassafras never seen tea bag found get taste remember needed bags per cup bags rather fragile really great product buy plus shipping time great \n",
            "Original summary: tea bags \n",
            "Predicted summary:  great tea\n",
            "\n",
            "\n",
            "Review: beef jerky lovers like jerky best tasting stuff ive found anywhere flavors great black peppered opinion best wood smoked little dry still good would recommend anybody \n",
            "Original summary: great stuff \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: really limit additives sugar son autism switch orange tangerine really fills bill feels like getting real fizzy soda mommy happy loaded chemicals additives actually real juice total win win \n",
            "Original summary: my son favorite soda \n",
            "Predicted summary:  great for\n",
            "\n",
            "\n",
            "Review: happy tea order price comes nice tin round tea bags great tasting add ginger chips really great upset stomach recently received second order \n",
            "Original summary: love this tea \n",
            "Predicted summary:  great tea\n",
            "\n",
            "\n",
            "Review: tastes great best aroma brewing subscribe save way go \n",
            "Original summary: one of the best flavored cups \n",
            "Predicted summary:  great coffee\n",
            "\n",
            "\n",
            "Review: live az cannot find one product anywhere makes chicken juicy tender flavor beyond compare happy able purchase looking forward buying \n",
            "Original summary: chicken is the best \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: favorite hot sauce buy locally love flavor hopefully flavors show amazon people enjoy favorites medium pineapple flavored ones far thank making flavorful hot sauce \n",
            "Original summary: tasty hot sauce \n",
            "Predicted summary:  great hot chocolate\n",
            "\n",
            "\n",
            "Review: give little background ordered great deal box single serving chips thought would give try variety flavors package great enjoy chips leave lot less mess average bags potato chips crumbs bag prepared like normal chips result differently chip personal taste whether like taste texture would highly recommend trying \n",
            "Original summary: excellent chips \n",
            "Predicted summary:  love these chips\n",
            "\n",
            "\n",
            "Review: really good gave people liked plain flavored ones take well using scoops dip salsa eating bbq flavored ones brings back years would eat bbq pork skins back truck range think pepper ones could use pepper still good make good snack side dish lunch cal per pack \n",
            "Original summary: great less \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: tried kona much cheaper brands using say greatly surprised mild bite acidity shopping list \n",
            "Original summary: excellent stuff price \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: chips good ended eating whole bag day cause good glad like lays \n",
            "Original summary: these chips tasted good \n",
            "Predicted summary:  great chips\n",
            "\n",
            "\n",
            "Review: works took one minutes later trying different things mouth last thing im trying right beer taste different trying new things give try read wont work people well work review \n",
            "Original summary: interesting \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: great product nice combination chocolates perfect size bags plenty shipped promptly kids neighborhood liked candies \n",
            "Original summary: awsome kids in loved us \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: purchased tea present looking sassafras tea long time realize hard find absolutely loves made great surprise christmas gift \n",
            "Original summary: hard to find tea \n",
            "Predicted summary:  great tea\n",
            "\n",
            "\n",
            "Review: made china even dog food gone way hershey back vendor looking made sold america \n",
            "Original summary: sticks pack of \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: children eat healthy products love graham crackers glad available amazon \n",
            "Original summary: excellent product \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: love soup healthy full bad ingredients like chicken noodle better rice pretty good \n",
            "Original summary: love wolfgang puck \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: much watery tastes much like tasteless hot cocoa one gets vending machine receiving box reading list ingredients decided order product definitely worth money \n",
            "Original summary: not good \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: really wanted yr old cat like treats already feed wellness wet food excellent perhaps used whiskas temptations normally give like jerky bits notice hard pick pretty flat texture used rd time gave treats looks like back less healthy alternative \n",
            "Original summary: not for my cat \n",
            "Predicted summary:  my dog loves it\n",
            "\n",
            "\n",
            "Review: received box assorted popchips days ago support weight watcher meal plan absolutely love find fit plan without hesitation recommend varieties chips great idea \n",
            "Original summary: yummy \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: used sons party one sweet treats great kids loved price fabulous way better purchasing elsewhere item came described fresh thank amazon com \n",
            "Original summary: great product at great price \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: discovered moved canada years back experienced thicker wasa crispbread bit put first dissolved first time ate one light laughing cow cheese little powdery would like compliment cheeses well without overwhelming \n",
            "Original summary: for those who want the \n",
            "Predicted summary:  gluten free baking\n",
            "\n",
            "\n",
            "Review: outstanding authentic dulce de leche number one argentina exceptional richness depth flavor made small dairy outside \n",
            "Original summary: love \n",
            "Predicted summary:  great coffee\n",
            "\n",
            "\n",
            "Review: received box christmas really good overly strong like black licorice indeed soft simple ingredient list high fructose corn syrup like candy flavor \n",
            "Original summary: real licorice \n",
            "Predicted summary:  great for\n",
            "\n",
            "\n",
            "Review: worked little sweetened fresh pineapple changed taste bit bitter sour orange help work anything else \n",
            "Original summary: miracle berry \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: delicious coffee ever mess stomach amazing tastes wonderful everyone work loves \n",
            "Original summary: delicious \n",
            "Predicted summary:  great coffee\n",
            "\n",
            "\n",
            "Review: terrific baby food beef spinach tastes great first meat baby food son would eat tasted quite good \n",
            "Original summary: excellent and great taste \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: really picky gum chew great flavor lasts long time recommend \n",
            "Original summary: great gum \n",
            "Predicted summary:  great hot chocolate\n",
            "\n",
            "\n",
            "Review: love using sweeten tea coffee etc tastes much better low glycemic sweeteners bitter aftertaste \n",
            "Original summary: great stuff \n",
            "Predicted summary:  great tea\n",
            "\n",
            "\n",
            "Review: fill dozen dd dark take work afternoon cup use home breakfast dose job economical problem bit grinds run machine dirty need every often let plug \n",
            "Original summary: great for work coffee \n",
            "Predicted summary:  great coffee\n",
            "\n",
            "\n",
            "Review: awesome really helped daughter gain much needed weight reasonable price business \n",
            "Original summary: great \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: enjoy rich flavored cheddar cheese bite would give try instant party favorite brought crackers friends house would recommend anyone \n",
            "Original summary: the best cheese you will ever eat \n",
            "Predicted summary:  great chips\n",
            "\n",
            "\n",
            "Review: everyone preferences know actually liked flavor wife tried could stand sweet guess second cup tend agree sweet \n",
            "Original summary: but too sweet \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: chose purchase quantity cheaper grocery store liked product knew getting \n",
            "Original summary: cheaper than the \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: bought mostly wanted peppermint hot cocoa fell love milk chocolate one peppermint pretty good well good cocoa \n",
            "Original summary: great \n",
            "Predicted summary:  great coffee\n",
            "\n",
            "\n",
            "Review: year old cocker spaniel loves food good needs lose pounds trick glad found amazon hard find elsewhere \n",
            "Original summary: happy dog \n",
            "Predicted summary:  my dog loves these\n",
            "\n",
            "\n",
            "Review: much one say hawaiian punch kids love took stars ordered oz bottles received oz bottles need smaller bottles kids pour going supermarket future hawaiian punch needs \n",
            "Original summary: wrong size \n",
            "Predicted summary:  great snack\n",
            "\n",
            "\n",
            "Review: love jalapeno chips kettle must try nice kick jalapeno delicious addicting recommended \n",
            "Original summary: crunchy and spicy \n",
            "Predicted summary:  great chips\n",
            "\n",
            "\n",
            "Review: kids loved great deal feel guilty giving kids chips \n",
            "Original summary: great snack \n",
            "Predicted summary:  great taste\n",
            "\n",
            "\n",
            "Review: figured must bacon like bacon used certain age remember deep smoky flavor good bacon cannot found store bacon anymore bacon thin lightly poorly smoked even called gourmet bacon old fashioned flavor thickness bacon way good old days arrives nice cool ice pack cheaper buy pack \n",
            "Original summary: what is to be \n",
            "Predicted summary:  great for\n",
            "\n",
            "\n",
            "Review: bought gift hard buy father loved bread said delicious \n",
            "Original summary: bread \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: like well signed subscription rate mail automatically every month choice eat lot roasted yet nuts taste better roasted looking forward \n",
            "Original summary: my first order received \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: love chips husband get variety pack great way flavor like packaged well always fresh bag contains generous portion purchased many times never dissapointed \n",
            "Original summary: great chip substitute \n",
            "Predicted summary:  great chips\n",
            "\n",
            "\n",
            "Review: hazelnut household favorite favorite thought would give cups try flavor smooth delightful suggest trying brand cup machine \n",
            "Original summary: yum \n",
            "Predicted summary:  great coffee\n",
            "\n",
            "\n",
            "Review: love ease green natural tea time tastes great love stash green tea \n",
            "Original summary: great product \n",
            "Predicted summary:  great tea\n",
            "\n",
            "\n",
            "Review: picky eaters like chicken liver hard find great deal \n",
            "Original summary: my love it \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: bought safeway awesome making homemade iced caramel cost starbucks \n",
            "Original summary: homemade caramel \n",
            "Predicted summary:  great coffee\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}